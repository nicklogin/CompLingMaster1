{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from string import punctuation\n",
    "from collections import defaultdict, Counter\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Задание 1</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2ch_corpus.txt','r',encoding='utf-8') as inp:\n",
    "    dvach = inp.read()\n",
    "\n",
    "with open('lenta.txt','r',encoding='utf-8') as inp:\n",
    "    news = inp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dvach = [['<pad>','<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach)]\n",
    "sentences_news = [['<pad>','<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(news)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инкапсулируем функционал 3-граммной модели в класс, а для хранения условных вероятностей воспользуемся разреженной матрицей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriGramModel:\n",
    "    def __init__(self, corpus,\n",
    "                 start_bigram = ('<pad>','<start>'),\n",
    "                 end_token = '<end>'):\n",
    "        self.corpus = corpus\n",
    "        self.start_bigram = start_bigram\n",
    "        self.end_token = end_token\n",
    "        self.create_matrix()\n",
    "    \n",
    "\n",
    "    def create_matrix(self):\n",
    "        unigrams = Counter(token for sent in self.corpus for token in sent[2:])\n",
    "        \n",
    "        self.id2word = [word for word in unigrams]\n",
    "        self.word2id = {word:i for i,word in enumerate(self.id2word)}\n",
    "        \n",
    "        bigrams = Counter((token1,token2) for sent in self.corpus for token1,\n",
    "                               token2 in zip(sent[:-2],sent[1:-1]))\n",
    "\n",
    "        self.id2bigram = [bigram for bigram in bigrams]\n",
    "        self.bigram2id = {bigram:i for i,bigram in enumerate(self.id2bigram)}\n",
    "        \n",
    "        trigrams = Counter((token1,token2,token3) for sent in self.corpus for token1,\n",
    "                            token2, token3 in zip(sent[:-2],sent[1:-1],sent[2:]))\n",
    "        \n",
    "        trigram_keys = [i for i in trigrams]\n",
    "        row_ind = [self.bigram2id[(i[0],i[1])] for i in trigram_keys]\n",
    "        col_ind = [self.word2id[i[2]] for i in trigram_keys]\n",
    "        data = [trigrams[i]/bigrams[(i[0],i[1])] for i in trigram_keys]\n",
    "        \n",
    "        self.matrix = csr_matrix((data,(row_ind,col_ind)), shape=(len(bigrams),len(unigrams)))\n",
    "        \n",
    "    \n",
    "    def generate_text(self, length=100):\n",
    "        text = []\n",
    "        bigram = self.start_bigram\n",
    "\n",
    "        for i in range(length):\n",
    "            bigram_id = self.bigram2id[bigram]\n",
    "            chosen = np.random.choice(self.matrix.shape[1], p=self.matrix[bigram_id].toarray()[0])\n",
    "            \n",
    "            new_token = self.id2word[chosen]\n",
    "            text.append(new_token)\n",
    "\n",
    "            if new_token == self.end_token:\n",
    "                bigram = self.start_bigram\n",
    "            else:\n",
    "                bigram = (bigram[1], new_token)\n",
    "\n",
    "        return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dvach = TriGramModel(sentences_dvach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978238, 189516)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dvach.matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на выдачу на основе \"двачевского\" текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "факты \n",
      "\n",
      " у вас синусы-косинусы зря столько раз дох что уже давно могилизовался бы за то что я самовлюбленный болван \n",
      "\n",
      " если красной ручкой ваше дело передано в прокуратуру а то и другое \n",
      "\n",
      " каждая вторая бабка от 30 августа потом снова будет ручкаться с эрдоганом \n",
      "\n",
      " собираюсь идти дальше \n",
      "\n",
      " надеюсь тебя поймают \n",
      "\n",
      " это уже аксиома \n",
      "\n",
      " в обоих был рак то еще и директор там прикольный дядька не высокомерный обычно-кун такой себе \n",
      "\n",
      " сижу тут чтобы доказать вам вашу ничтожность и превосходство тян над кунами \n",
      "\n",
      " хорошь вестись на толстоту тема про 4 20 pm вроде кошаков\n"
     ]
    }
   ],
   "source": [
    "print(model_dvach.generate_text().replace('<end>','\\n\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И на основе новостных текстов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_news = TriGramModel(sentences_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748147, 116303)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_news.matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в то же время ар напоминает что клинтоновская администрация обещала обеспечить российских ядерщиков подобной техникой если москва не изменит своей позиции которая гораздо мягче в отношении россии \n",
      "\n",
      " кроме того утверждены президиум фракции из 11 человек будут иметь совокупно 65-процентный пакет акций компании notharvard com уже перегруженная именами и разборками вокруг этих запасов может причинить серьезный ущерб городу-курорту сочи \n",
      "\n",
      " помимо этого райков сообщил что начальник флотской контрразведки оклеветал его в 2006 году и составляющего не более чем зыбкой на сайте fnsi \n",
      "\n",
      " в заключение президент франции жак ширак сообщает интерфакс россиянин признан виновным в организации терактов в стране отнюдь\n"
     ]
    }
   ],
   "source": [
    "print(model_news.generate_text().replace('<end>','\\n\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Вывод</b>: По сравнению с биграммной моделью, реализованной в <a href=\"\">семинарской тетрадке</a>, предложения, сгенерированные триграммной моделью получаются борлее длинными, согласованными (допустимыми грамматикой русской языка) и осмысленными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Задание 2</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words('russian') + [\"это\", \"весь\"])\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "def normalize(text):\n",
    "    tokens = re.findall('[а-яёa-z0-9]+', text.lower())\n",
    "    normalized_text = [morph.parse(word)[0].normal_form for word \\\n",
    "                                                            in tokens]\n",
    "    normalized_text = [word for word in normalized_text if len(word) > 2 and word not in stops]\n",
    "    \n",
    "    return normalized_text\n",
    "\n",
    "def preprocess(text):\n",
    "    sents = sentenize(text)\n",
    "    return [normalize(sent.text) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser, original_scorer, npmi_scorer\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним формулу PMI и имплементируем эту метрику:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$PMI=log\\frac{p(xy)}{p(x)p(y)}=log\\frac{count(xy)/N}{(count(x)/N)(count(y)/N)} = log(count(xy))+log(N)-log(count(x))-log(count(y))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PMI(worda_count, wordb_count, bigram_count,\n",
    "       len_vocab, min_count, corpus_word_count):\n",
    "    return log(bigram_count)+log(corpus_word_count)-log(worda_count)-log(wordb_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = preprocess(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем предложение на котором будем тестировать модели Phrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = corpus[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['русский', 'инвалид', 'сентябрь', '1914', 'год', 'министерство', 'народный', 'просвещение', 'вид', 'происходить', 'чрезвычайный', 'событие', 'признать', 'соответственный', 'день', 'годовщина', 'день', 'рождение', 'лермонтов', 'октябрь', '1914', 'год', 'ограничиться', 'совершение', 'учебный', 'заведение', 'панихида', 'поэт', 'отложить', 'празднование', 'юбилей', 'благоприятный', 'время']\n"
     ]
    }
   ],
   "source": [
    "print(test_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаем получить следующие значимые N-граммы - <i>министерство народного просвещения, 1914 год, чрезвычайное событие, день рождения, учебное заведение, празднование юбилея, благоприятное время</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Phrases(corpus,threshold=2,scoring=PMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0: ['русский_инвалид', 'сентябрь', '1914', 'год_министерство', 'народный', 'просвещение', 'вид_происходить', 'чрезвычайный', 'событие', 'признать', 'соответственный', 'день_годовщина', 'день_рождение', 'лермонтов', 'октябрь', '1914', 'год', 'ограничиться', 'совершение', 'учебный_заведение', 'панихида', 'поэт', 'отложить', 'празднование', 'юбилей', 'благоприятный', 'время']\n",
      "Threshold=1: ['русский_инвалид', 'сентябрь', '1914', 'год', 'министерство', 'народный', 'просвещение', 'вид', 'происходить', 'чрезвычайный', 'событие_признать', 'соответственный', 'день_годовщина', 'день_рождение', 'лермонтов', 'октябрь', '1914', 'год_ограничиться', 'совершение_учебный', 'заведение_панихида', 'поэт', 'отложить', 'празднование', 'юбилей', 'благоприятный', 'время']\n",
      "Threshold=2: ['русский_инвалид', 'сентябрь', '1914', 'год', 'министерство', 'народный', 'просвещение', 'вид_происходить', 'чрезвычайный_событие', 'признать', 'соответственный', 'день_годовщина', 'день_рождение', 'лермонтов', 'октябрь', '1914', 'год', 'ограничиться_совершение', 'учебный_заведение', 'панихида', 'поэт', 'отложить', 'празднование', 'юбилей', 'благоприятный', 'время']\n",
      "Threshold=3: ['русский_инвалид', 'сентябрь', '1914', 'год', 'министерство', 'народный', 'просвещение', 'вид', 'происходить_чрезвычайный', 'событие', 'признать', 'соответственный', 'день_годовщина', 'день_рождение', 'лермонтов', 'октябрь', '1914', 'год', 'ограничиться_совершение', 'учебный_заведение', 'панихида', 'поэт', 'отложить', 'празднование', 'юбилей_благоприятный', 'время']\n",
      "Threshold=4: ['русский_инвалид', 'сентябрь', '1914', 'год', 'министерство', 'народный', 'просвещение', 'вид', 'происходить_чрезвычайный', 'событие', 'признать', 'соответственный', 'день_годовщина', 'день_рождение', 'лермонтов', 'октябрь', '1914', 'год', 'ограничиться_совершение', 'учебный_заведение', 'панихида', 'поэт', 'отложить_празднование', 'юбилей_благоприятный', 'время']\n",
      "Threshold=5: ['русский_инвалид', 'сентябрь_1914', 'год', 'министерство', 'народный', 'просвещение', 'вид', 'происходить_чрезвычайный', 'событие', 'признать', 'соответственный', 'день', 'годовщина', 'день_рождение', 'лермонтов', 'октябрь', '1914', 'год', 'ограничиться_совершение', 'учебный_заведение', 'панихида', 'поэт', 'отложить_празднование', 'юбилей_благоприятный', 'время']\n",
      "Threshold=6: ['русский', 'инвалид', 'сентябрь_1914', 'год', 'министерство', 'народный', 'просвещение', 'вид', 'происходить', 'чрезвычайный', 'событие', 'признать', 'соответственный', 'день', 'годовщина', 'день', 'рождение', 'лермонтов', 'октябрь_1914', 'год', 'ограничиться_совершение', 'учебный_заведение', 'панихида_поэт', 'отложить', 'празднование_юбилей', 'благоприятный', 'время']\n",
      "Threshold=7: ['русский', 'инвалид', 'сентябрь_1914', 'год', 'министерство', 'народный', 'просвещение', 'вид', 'происходить', 'чрезвычайный', 'событие', 'признать_соответственный', 'день', 'годовщина', 'день', 'рождение', 'лермонтов', 'октябрь', '1914', 'год', 'ограничиться', 'совершение', 'учебный_заведение', 'панихида', 'поэт', 'отложить', 'празднование_юбилей', 'благоприятный', 'время']\n",
      "Threshold=8: ['русский', 'инвалид', 'сентябрь', '1914', 'год', 'министерство', 'народный', 'просвещение', 'вид', 'происходить', 'чрезвычайный', 'событие', 'признать', 'соответственный', 'день', 'годовщина', 'день', 'рождение_лермонтов', 'октябрь', '1914', 'год', 'ограничиться', 'совершение', 'учебный_заведение', 'панихида', 'поэт', 'отложить', 'празднование_юбилей', 'благоприятный', 'время']\n",
      "Threshold=9: ['русский', 'инвалид', 'сентябрь', '1914', 'год', 'министерство', 'народный', 'просвещение', 'вид', 'происходить', 'чрезвычайный', 'событие', 'признать', 'соответственный', 'день', 'годовщина', 'день', 'рождение', 'лермонтов', 'октябрь', '1914', 'год', 'ограничиться', 'совершение', 'учебный', 'заведение', 'панихида_поэт', 'отложить', 'празднование', 'юбилей', 'благоприятный', 'время']\n"
     ]
    }
   ],
   "source": [
    "for threshold in range(10):\n",
    "    model1 = Phrases(corpus,threshold=threshold,scoring=PMI)\n",
    "    phraser1 = Phraser(model1)\n",
    "    model2 = Phrases(phraser1[corpus],threshold=threshold,scoring=PMI)\n",
    "    phraser2 = Phraser(model2)\n",
    "    print(f\"Threshold={threshold}: {model2[test_sentence]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Вывод</b>: Коллокация <i>министерство народного просвещения</i> не находится моделью ввиду малой представленности исторических новостей в корпусе. При повышении порога PMI до 1 пропадает ложная коллокация <i>год просвещения</i>, а при повышении до 2 коллокация <i>событие признать</i>. При повышения порога до 9 модель перестаёт обнаруживать коллокации в тестовом предложении. Из ожидаемых коллокаций были обнаружены <i>чрезвычайное событие</i>(при пороге=3), <i>день рождения</i> (при пороге от 1 до 5), <i>учебное завдение</i> (при пороге равном 0 и от 2 до 8), <i>празднование юбилея</i> (при пороге от 6 до 8). При значениях порога от 0 до 9 включительно модель не обнаружила ни одной значимой 3-граммы. Также следует отметить, что при повышении порога некоторые словосочетания, не прошедшие порог коллокационной силы на первом уровне проходили его на втором (в уже забиграммленном тексте), в связи с чем повышение порога могло приводить к появлению новых коллокаций (в отличие от одноуровневой модели, где повышение порога только сокращало было ранее обнаруженный набор коллокаций)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('diploma_env': virtualenv)",
   "language": "python",
   "name": "python37364bitdiplomaenvvirtualenvf0eeb467a8c8415c81654258b27dd205"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
