{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скачаем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen('https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/zhivago.txt') as inp:\n",
    "    text = inp.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(text):\n",
    "    text = re.sub(r'<(binary|program-used|src-url|lang|id|version|nickname|date)[^>]*>[^<]*</\\1>', ' ', text)\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    text = re.sub('  +', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = clear(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Борис Леонидович Пастернак \\n Доктор Живаго \\n «Доктор Живаго» - итоговое произведение Бориса Пастернака, книга всей его жизни. Этот роман принес его автору мировую известность и Нобелевскую премию, присуждение которой обернулось для поэта оголтелой политической травлей, обвинениями в «измене Родине» и в результате стоило ему жизни. \\n «Доктор Живаго» - роман, сама ткань которого убедительнее свидетельствует о чуде, чем все размышления доктора и обобщения автора. Человек, который так пишет, бесконечно много пережил и передумал, и главные его чувства на свете - восхищенное умиление и слезное сострадание; конечно, есть в его мире место и презрению, и холодному отстранению - но не в них суть. Роман Пастернака - оплакивание прежних заблуждений и их жертв; те, кто не разделяет молитвенного восторга перед миром, достойны прежде всего жалости. Перечитывать «Доктора Живаго» стоит именно тогда, когда кажется, что жить не стоит. Тогда десять строк из этого романа могут сделать то же, что делает любовь в одном из стихотворений доктора: «Жизнь вернулась так же беспричинно, как когда-то странно прервалась» . \\n \\n \\n Борис Пастернак \\n Доктор Живаго \\n И ДЫШАТ ПОЧВА И СУДЬБА \\n Спустя два года после завершения романа «Доктор Живаго» Борис Пастернак писал: \\n «Я думаю, несмотря на привычность всего того, что продолжает стоять перед нашими глазами и что мы продолжаем слышать и читать, ничего этого больше нет, это уже прошло и состоялось, огромный, неслыханных сил стоивший период закончился и миновал. Освободилось безмерно большое, покамест пустое и не занятое место для нового и еще не бывалого, для того, что будет угадано чьей-либо гениальной независимостью и свежестью, для того, что внушит и подскажет жизнь новых чисел и дней. Сейчас мукою художников будет не то, признаны ли они и признаны ли будут застаивающейся, запоздалой политической современностью или властью, но неспособность совершенно оторваться от понятий, ставших привычными, забыть навязывающиеся навыки, нарушить непрерывность. Н'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rusenttokenize import ru_sent_tokenize\n",
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_punct(text):\n",
    "    text = re.sub('\\W',' ',text)\n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    return text.strip()\n",
    "\n",
    "def my_tokenize(text):\n",
    "    return [token.text for token in tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Дорогие уважаемые друзья товарищи давайте жить дружно'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_punct(\"Дорогие, уважаемые друзья-товарищи, давайте жить дружно!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = [my_tokenize(rm_punct(sent)) for sent in ru_sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['борис', 'леонидович', 'пастернак', 'доктор', 'живаго', 'доктор', 'живаго', 'итоговое', 'произведение', 'бориса', 'пастернака', 'книга', 'всей', 'его', 'жизни'], ['этот', 'роман', 'принес', 'его', 'автору', 'мировую', 'известность', 'и', 'нобелевскую', 'премию', 'присуждение', 'которой', 'обернулось', 'для', 'поэта', 'оголтелой', 'политической', 'травлей', 'обвинениями', 'в', 'измене', 'родине', 'и', 'в', 'результате', 'стоило', 'ему', 'жизни'], ['доктор', 'живаго', 'роман', 'сама', 'ткань', 'которого', 'убедительнее', 'свидетельствует', 'о', 'чуде', 'чем', 'все', 'размышления', 'доктора', 'и', 'обобщения', 'автора']]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_sentences[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдём повторяющиеся предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rep_sents(sent_list):\n",
    "    sent_list = [tuple(sent) for sent in sent_list]\n",
    "    \n",
    "    rep_sents = dict()\n",
    "    \n",
    "    for sent in set(sent_list):\n",
    "        sent_count = sent_list.count(sent)\n",
    "        if sent_count > 1:\n",
    "            rep_sents[sent] = sent_count\n",
    "    return rep_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_sents = find_rep_sents(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('странно',): 2,\n",
       " ('свеча', 'горела', 'на', 'столе', 'свеча', 'горела'): 3,\n",
       " ('да',): 2,\n",
       " ('толпа', 'росла'): 2,\n",
       " ('прорыв',): 2,\n",
       " ('он', 'открыл', 'глаза'): 2,\n",
       " ('парило',): 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой самый частотный токен в тексте длинее 6 символов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = Counter([tok for sent in tokenized_sentences for tok in sent if len(tok) > 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('андреевич', 289)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict.most_common(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_sentences = [[(word, stemmer.stem(word)) for word in sent] for sent in tokenized_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим какие варианты нашлись у каких стем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_n_stems = [word for sent in stemmed_sentences for word in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('борис', 'борис'),\n",
       " ('леонидович', 'леонидович'),\n",
       " ('пастернак', 'пастернак'),\n",
       " ('доктор', 'доктор'),\n",
       " ('живаго', 'живаг'),\n",
       " ('доктор', 'доктор'),\n",
       " ('живаго', 'живаг'),\n",
       " ('итоговое', 'итогов'),\n",
       " ('произведение', 'произведен'),\n",
       " ('бориса', 'борис'),\n",
       " ('пастернака', 'пастернак'),\n",
       " ('книга', 'книг'),\n",
       " ('всей', 'все'),\n",
       " ('его', 'ег'),\n",
       " ('жизни', 'жизн'),\n",
       " ('этот', 'этот'),\n",
       " ('роман', 'рома'),\n",
       " ('принес', 'принес'),\n",
       " ('его', 'ег'),\n",
       " ('автору', 'автор')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_n_stems[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдём для каждой основы её частоту, её варианты и частоты вариантов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_freqs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems = set([i[1] for i in tokens_n_stems])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k1l77\\python_envs\\diploma_env\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380a6a789eb9417592c8d8cc55fcd0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17975.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for stem in tqdm_notebook(stems,total=len(stems)):\n",
    "    stem_info = {'stem': stem}\n",
    "    stem_variants = [entry[0] for entry in tokens_n_stems if entry[1] == stem]\n",
    "    stem_info['frequency'] = len(stem_variants)\n",
    "    variant_freqs = dict(Counter(stem_variants))\n",
    "    stem_info['variant_freqs'] = variant_freqs\n",
    "    stem_freqs.append(stem_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_freqs = sorted(stem_freqs, key=lambda x: x['frequency'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы не засорять ноутбук, сохраним отсортированные по частоте основы с вариантами в отдельный файл. Наблюдение ниже основано на данных этого файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stem_freqs.json', 'w', encoding='utf-8') as outp:\n",
    "    json.dump(stem_freqs, outp, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частые ошибки:\n",
    "\n",
    "    друг и другой; надо, надеюсь и Надя; меня и менее; да и дай; часть и частый; сторона и сторониться; вас и Вася; пол, полу-, полый, полено и поле"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдём слова более 4 символов, которые не изменились после стемминга:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_changed = [entry for entry in stem_freqs if entry['stem'] in entry['variant_freqs'] and len(entry['stem'])>4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_changed = sorted(not_changed, key=lambda x: x['frequency'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним отобранные основы в файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('not_changed.json', 'w', encoding='utf-8') as outp:\n",
    "    json.dump(not_changed, outp, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе наблюдений над файлом получим следующий вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слова, не изменившиеся после стемминга: <i>может</i>, <i>сидел</i>, <i>ветер</i>, <i>тянул</i>, <i>ненавидел</i>, <i>построек</i>, <i>чисел</i>, <i>винтовок</i>, <i>непорядок</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['а', 'без', 'более', 'больше', 'будет', 'будто', 'бы', 'был', 'была', 'были', 'было', 'быть', 'в', 'вам', 'вас', 'вдруг', 'ведь', 'во', 'вот', 'впрочем', 'все', 'всегда', 'всего', 'всех', 'всю', 'вы', 'где', 'да', 'даже', 'два', 'для', 'до', 'другой', 'его', 'ее', 'ей', 'ему', 'если', 'есть', 'еще', 'ж', 'же', 'за', 'зачем', 'здесь', 'и', 'из', 'или', 'им', 'иногда', 'их', 'к', 'как', 'какая', 'какой', 'когда', 'конечно', 'кто', 'куда', 'ли', 'лучше', 'между', 'меня', 'мне', 'много', 'может', 'можно', 'мой', 'моя', 'мы', 'на', 'над', 'надо', 'наконец', 'нас', 'не', 'него', 'нее', 'ней', 'нельзя', 'нет', 'ни', 'нибудь', 'никогда', 'ним', 'них', 'ничего', 'но', 'ну', 'о', 'об', 'один', 'он', 'она', 'они', 'опять', 'от', 'перед', 'по', 'под', 'после', 'потом', 'потому', 'почти', 'при', 'про', 'раз', 'разве', 'с', 'сам', 'свою', 'себе', 'себя', 'сейчас', 'со', 'совсем', 'так', 'такой', 'там', 'тебя', 'тем', 'теперь', 'то', 'тогда', 'того', 'тоже', 'только', 'том', 'тот', 'три', 'тут', 'ты', 'у', 'уж', 'уже', 'хорошо', 'хоть', 'чего', 'чем', 'через', 'что', 'чтоб', 'чтобы', 'чуть', 'эти', 'этого', 'этой', 'этом', 'этот', 'эту', 'я']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(stopwords.words('russian')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также следует добавить слова:\n",
    "    \n",
    "     ними - Местоимение 3л. Мн. ч. Тв. п. Остальные личные местоимения в списке есть\n",
    "     снова -  В списке есть \"опять\"\n",
    "     ничем, ничему - формы от \"ничего\"\n",
    "     тому - Д.п. от \"тот\", отсутствующая форма в списке\n",
    "     тобой - Тв. п. от \"ты\", отсутствующая форма в списке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_text.txt', 'w', encoding='utf-8') as outp:\n",
    "    outp.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mystem -d --format json input_text.txt text_parsed.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_parsed.json', 'r', encoding='utf-8') as inp:\n",
    "    json_out = inp.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исправим mystem'овский json так, чтобы он был валидным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_out = '[' + re.sub('\\n(?!\")',',\\n',json_out)[:-2] + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_lemmatized = json.loads(json_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'analysis': [{'lex': 'борис'}], 'text': 'борис'},\n",
       "  {'analysis': [{'lex': 'леонидович'}], 'text': 'леонидович'},\n",
       "  {'analysis': [{'lex': 'пастернак'}], 'text': 'пастернак'}],\n",
       " [{'analysis': [{'lex': 'доктор'}], 'text': 'доктор'},\n",
       "  {'analysis': [{'lex': 'живаго'}], 'text': 'живаго'}]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_lemmatized[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем то же самое при помощи pymorphy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymorphy_lemmatized = [[(token, morph.parse(token)[0].normal_form) for token in sent] for sent in tokenized_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('борис', 'борис'),\n",
       "  ('леонидович', 'леонидович'),\n",
       "  ('пастернак', 'пастернак'),\n",
       "  ('доктор', 'доктор'),\n",
       "  ('живаго', 'живаго'),\n",
       "  ('доктор', 'доктор'),\n",
       "  ('живаго', 'живаго'),\n",
       "  ('итоговое', 'итоговый'),\n",
       "  ('произведение', 'произведение'),\n",
       "  ('бориса', 'борис'),\n",
       "  ('пастернака', 'пастернак'),\n",
       "  ('книга', 'книга'),\n",
       "  ('всей', 'весь'),\n",
       "  ('его', 'он'),\n",
       "  ('жизни', 'жизнь')],\n",
       " [('этот', 'этот'),\n",
       "  ('роман', 'роман'),\n",
       "  ('принес', 'принести'),\n",
       "  ('его', 'он'),\n",
       "  ('автору', 'автор'),\n",
       "  ('мировую', 'мировой'),\n",
       "  ('известность', 'известность'),\n",
       "  ('и', 'и'),\n",
       "  ('нобелевскую', 'нобелевский'),\n",
       "  ('премию', 'премия'),\n",
       "  ('присуждение', 'присуждение'),\n",
       "  ('которой', 'который'),\n",
       "  ('обернулось', 'обернуться'),\n",
       "  ('для', 'для'),\n",
       "  ('поэта', 'поэт'),\n",
       "  ('оголтелой', 'оголтелый'),\n",
       "  ('политической', 'политический'),\n",
       "  ('травлей', 'травля'),\n",
       "  ('обвинениями', 'обвинение'),\n",
       "  ('в', 'в'),\n",
       "  ('измене', 'измена'),\n",
       "  ('родине', 'родина'),\n",
       "  ('и', 'и'),\n",
       "  ('в', 'в'),\n",
       "  ('результате', 'результат'),\n",
       "  ('стоило', 'стоить'),\n",
       "  ('ему', 'он'),\n",
       "  ('жизни', 'жизнь')]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymorphy_lemmatized[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведём сравнение - посмотрим какие токены MyStem и PyMorphy лемматизировали по-разному:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mystem_lemma(item):\n",
    "    if item['analysis']:\n",
    "        return item['analysis'][0]['lex']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "mystem_flat = [(item['text'], get_mystem_lemma(item)) for sent in mystem_lemmatized for item in sent]\n",
    "pymorphy_flat = [item for sent in pymorphy_lemmatized for item in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID Mystem(Токен, Лемма) PyMorphy(токен, Лемма)\n",
      "13 ('его', 'его') ('его', 'он')\n",
      "17 ('принес', 'приносить') ('принес', 'принести')\n",
      "27 ('обернулось', 'обертываться') ('обернулось', 'обернуться')\n",
      "49 ('убедительнее', 'убедительно') ('убедительнее', 'убедительный')\n",
      "54 ('все', 'весь') ('все', 'всё')\n",
      "66 ('пережил', 'переживать') ('пережил', 'пережить')\n",
      "68 ('передумал', 'передумывать') ('передумал', 'передумать')\n",
      "71 ('его', 'его') ('его', 'он')\n",
      "75 ('восхищенное', 'восхищенный') ('восхищенное', 'восхитить')\n",
      "78 ('слезное', 'слезный') ('слезное', 'слёзный')\n",
      "81 ('есть', 'быть') ('есть', 'есть')\n",
      "83 ('его', 'его') ('его', 'он')\n",
      "95 ('суть', 'суть') ('суть', 'быть')\n",
      "102 ('их', 'их') ('их', 'они')\n",
      "114 ('всего', 'все') ('всего', 'весь')\n",
      "119 ('стоит', 'стоять') ('стоит', 'стоить')\n",
      "132 ('этого', 'этот') ('этого', 'это')\n",
      "150 ('беспричинно', 'беспричинный') ('беспричинно', 'беспричинно')\n",
      "4607 ('его', 'его') ('его', 'он')\n",
      "6523 ('его', 'его') ('его', 'он')\n",
      "14310 ('остановился', 'останавливаться') ('остановился', 'остановиться')\n",
      "38940 ('его', 'его') ('его', 'он')\n",
      "62441 ('его', 'его') ('его', 'он')\n",
      "72282 ('его', 'его') ('его', 'он')\n",
      "74794 ('этом', 'этот') ('этом', 'это')\n",
      "80595 ('ее', 'ее') ('ее', 'она')\n",
      "92875 ('все', 'весь') ('все', 'всё')\n",
      "101580 ('еще', 'еще') ('еще', 'ещё')\n",
      "104322 ('ее', 'ее') ('ее', 'она')\n",
      "118282 ('ее', 'ее') ('ее', 'она')\n",
      "125272 ('это', 'этот') ('это', 'это')\n",
      "128905 ('их', 'их') ('их', 'они')\n"
     ]
    }
   ],
   "source": [
    "print('Token ID', 'Mystem(Токен, Лемма)', 'PyMorphy(токен, Лемма)')\n",
    "\n",
    "for idx, (item_mystem, item_pymorphy) in enumerate(zip(mystem_flat, pymorphy_flat)):\n",
    "    if item_mystem[1] != item_pymorphy[1] and item_mystem[0] == item_pymorphy[0]:\n",
    "        print(idx, item_mystem, item_pymorphy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат сравнения:\n",
    "\n",
    " - MyStem - возводит глаголы к форме несовершенного вида, в то время как PyMorphy сохраняет вид\n",
    " - MyStem в отличие от PyMorphy не возводит к форме именительного падежа личные местоимения, но при этом возводит местоимение <i>все</i> к форме <i>весь</i>\n",
    "\n",
    "Интересные случаи:\n",
    "\n",
    " ID 49 убедительнее - убедительно (MyStem) vs. убедительный (PyMorphy)\n",
    " \n",
    " ID 75 восхищенное - восхищенный (MyStem) vs. восхитить (PyMorphy)\n",
    " \n",
    " ID 81 есть - быть (MyStem) vs. есть (PyMorphy)\n",
    " \n",
    " ID 95 суть - суть (MyStem) vs. быть (PyMorphy)\n",
    " \n",
    " ID 150 беспричинно - беспричинный (MyStem) vs. беспричинно (PyMorphy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('живаго', 'живаго') ('живаго', 'живаго')\n",
      "1 ('роман', 'роман') ('роман', 'роман')\n",
      "2 ('сама', 'сам') ('сама', 'сам')\n",
      "3 ('ткань', 'ткань') ('ткань', 'ткань')\n",
      "4 ('которого', 'который') ('которого', 'который')\n",
      "5 ('убедительнее', 'убедительно') ('убедительнее', 'убедительный')\n",
      "6 ('свидетельствует', 'свидетельствовать') ('свидетельствует', 'свидетельствовать')\n",
      "7 ('о', 'о') ('о', 'о')\n",
      "8 ('чуде', 'чудо') ('чуде', 'чудо')\n",
      "9 ('чем', 'чем') ('чем', 'чем')\n",
      "10 ('все', 'весь') ('все', 'всё')\n",
      "11 ('размышления', 'размышление') ('размышления', 'размышление')\n",
      "12 ('доктора', 'доктор') ('доктора', 'доктор')\n",
      "13 ('и', 'и') ('и', 'и')\n"
     ]
    }
   ],
   "source": [
    "for idx, (item_mystem, item_pymorphy) in enumerate(zip(mystem_flat[44:58], pymorphy_flat[44:58])):\n",
    "    print(idx, item_mystem, item_pymorphy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('главные', 'главный') ('главные', 'главный')\n",
      "1 ('его', 'его') ('его', 'он')\n",
      "2 ('чувства', 'чувство') ('чувства', 'чувство')\n",
      "3 ('на', 'на') ('на', 'на')\n",
      "4 ('свете', 'свет') ('свете', 'свет')\n",
      "5 ('восхищенное', 'восхищенный') ('восхищенное', 'восхитить')\n",
      "6 ('умиление', 'умиление') ('умиление', 'умиление')\n",
      "7 ('и', 'и') ('и', 'и')\n",
      "8 ('слезное', 'слезный') ('слезное', 'слёзный')\n",
      "9 ('сострадание', 'сострадание') ('сострадание', 'сострадание')\n"
     ]
    }
   ],
   "source": [
    "for idx, (item_mystem, item_pymorphy) in enumerate(zip(mystem_flat[70:80], pymorphy_flat[70:80])):\n",
    "    print(idx, item_mystem, item_pymorphy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('конечно', 'конечно') ('конечно', 'конечно')\n",
      "1 ('есть', 'быть') ('есть', 'есть')\n",
      "2 ('в', 'в') ('в', 'в')\n",
      "3 ('его', 'его') ('его', 'он')\n",
      "4 ('мире', 'мир') ('мире', 'мир')\n",
      "5 ('место', 'место') ('место', 'место')\n",
      "6 ('и', 'и') ('и', 'и')\n",
      "7 ('презрению', 'презрение') ('презрению', 'презрение')\n",
      "8 ('и', 'и') ('и', 'и')\n",
      "9 ('холодному', 'холодный') ('холодному', 'холодный')\n"
     ]
    }
   ],
   "source": [
    "for idx, (item_mystem, item_pymorphy) in enumerate(zip(mystem_flat[80:90], pymorphy_flat[80:90])):\n",
    "    print(idx, item_mystem, item_pymorphy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('отстранению', 'отстранение') ('отстранению', 'отстранение')\n",
      "1 ('но', 'но') ('но', 'но')\n",
      "2 ('не', 'не') ('не', 'не')\n",
      "3 ('в', 'в') ('в', 'в')\n",
      "4 ('них', 'они') ('них', 'они')\n",
      "5 ('суть', 'суть') ('суть', 'быть')\n",
      "6 ('роман', 'роман') ('роман', 'роман')\n",
      "7 ('пастернака', 'пастернак') ('пастернака', 'пастернак')\n",
      "8 ('оплакивание', 'оплакивание') ('оплакивание', 'оплакивание')\n",
      "9 ('прежних', 'прежний') ('прежних', 'прежний')\n"
     ]
    }
   ],
   "source": [
    "for idx, (item_mystem, item_pymorphy) in enumerate(zip(mystem_flat[90:100], pymorphy_flat[90:100])):\n",
    "    print(idx, item_mystem, item_pymorphy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('доктора', 'доктор') ('доктора', 'доктор')\n",
      "1 ('жизнь', 'жизнь') ('жизнь', 'жизнь')\n",
      "2 ('вернулась', 'вернуться') ('вернулась', 'вернуться')\n",
      "3 ('так', 'так') ('так', 'так')\n",
      "4 ('же', 'же') ('же', 'же')\n",
      "5 ('беспричинно', 'беспричинный') ('беспричинно', 'беспричинно')\n",
      "6 ('как', 'как') ('как', 'как')\n",
      "7 ('когда-то', 'когда-то') ('когда', 'когда')\n",
      "8 ('странно', 'странно') ('то', 'то')\n",
      "9 ('прервалась', 'прерываться') ('странно', 'странно')\n"
     ]
    }
   ],
   "source": [
    "for idx, (item_mystem, item_pymorphy) in enumerate(zip(mystem_flat[145:155], pymorphy_flat[145:155])):\n",
    "    print(idx, item_mystem, item_pymorphy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Вывод</b>: В целои, MyStem и PyMorphy одинаково хорошо справляются с лемматизацией текста. Недостатками MyStem перед PyMorphy являются возведение всех глаголов к форме несовершенного вида и отсутствие приведения к нормальной форме. Преимуществом MyStem перед PyMorphy является лемматизация с учётом контекста (см. пример с <i>суть</i>/<i>быть</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('diploma_env': virtualenv)",
   "language": "python",
   "name": "python37364bitdiplomaenvvirtualenvf0eeb467a8c8415c81654258b27dd205"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
